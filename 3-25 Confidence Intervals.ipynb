{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Intervals\n",
    "\n",
    "A common task is to use the result of our point estimator together with its mean square error to compute an interval in which we expect to often see the parameter of interest. Again we will assign a level of confidence to this statement in the form of a probability, and our interpretation of that is that it is a statement about the repeatability of the result. \n",
    "\n",
    "## Example\n",
    "\n",
    "We are going to sample an exponential random variable $Y$ once and use that value to estimate the mean $\\theta$ of the distribution.  We will then use the value of $Y$ to construct an interval in which we are 99% confident we will find $\\theta$.\n",
    "\n",
    "The PDF for the distribution is therefore:\n",
    "\n",
    "$$ f(y) = \\left\\{ \\begin{matrix} \\frac{1}{\\theta} e^{-y/\\theta} & y \\geq 0 \\\\ 0 & \\mbox{otherwise} \\end{matrix} \\right. $$\n",
    "\n",
    "The standard exponential (the exponential distribution with mean 1) is found from $Y$ by scaling it by $\\theta$:  \n",
    "\n",
    "$$ U = Y / \\theta $$ \n",
    "\n",
    "will have the distribution \n",
    "\n",
    "$$ f_U(u) = \\left\\{ \\begin{matrix} e^{-u} & u \\geq 0 \\\\ 0 & \\mbox{otherwise} \\end{matrix} \\right. $$\n",
    "\n",
    "Which we need because this is the exponential distribution encoded in scipy.stats.expon.\n",
    "\n",
    "We need to find two numbers $a$ and $b$ such that \n",
    "\n",
    "$$ P(a < U < b) = 0.99 $$\n",
    "\n",
    "Usually we would do this so that the tails are symmetric:\n",
    "\n",
    "$$ P( U < a) = 0.005 \\quad \\mbox{and} \\quad P(U > b) = 0.005 $$\n",
    "\n",
    "However it is worth noting that there are cases where we might want to have this be asymmetric such as by taking a=0 and choosing the b tail to have size 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's bring in the relevant distribution\n",
    "\n",
    "from scipy.stats import expon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005012541823544282"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can find a by using the ppf, the inverse cdf:\n",
    "\n",
    "a = expon.ppf(0.005)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check with the CDF that this is the left tail at size 0.005\n",
    "\n",
    "expon.cdf(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.298317366548035"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To find b we need to take 1 - 0.005 as our inverse for the cdf:\n",
    "\n",
    "b = expon.ppf(1-0.005)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the density between a and b is the 0.99 we want\n",
    "\n",
    "expon.cdf(b) - expon.cdf(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note why this example is not symmetric:  We are using a distribution that is skewed left and only supported from $[0, \\infty)$.\n",
    "\n",
    "Okay so we have that:\n",
    "\n",
    "$$ 0.99 = P(a < \\frac{Y}{\\theta} < b ) $$ \n",
    "\n",
    "and therefore solving for $\\theta$ we get:\n",
    "\n",
    "$$ 0.99 = P( \\frac{Y}{b} < \\theta < \\frac{Y}{a} ) $$\n",
    "\n",
    "Noting that we had to flip the inequalities when we took the reciprical. \n",
    "\n",
    "#### Suppose $Y= 5$\n",
    "\n",
    "Then our conclusion is that there is a 99% probability that the mean of the exponential distribution we just sampled is in the interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9436958290887744, 997.4979114417815)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5/b, 5/a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why so big?\n",
    "\n",
    "This interval is huge!  Why is it so big?\n",
    "\n",
    "Again we see these competing tensions:  adjusting our confidence will adjust the size of the region we end up with; and sampling our variable enough times will change the distribution for our point estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Point Estimate from a Sample\n",
    "\n",
    "Consider the following sample from the exponential distribution with mean $\\theta$.  Let's pretend we do not know what $\\theta$ is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.14507929,  0.67014224,  6.99290417,  9.32904158,  1.73986975,\n",
       "        3.31643215,  1.66717348, 26.28050942,  2.27332064,  0.70717216,\n",
       "       14.06590027, 23.07286012, 13.13140282, 10.54802346,  0.83651637,\n",
       "        7.30800148,  4.54687187,  5.21351631,  8.12527497,  8.44436276])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 20\n",
    "sample = expon.rvs(size=n)*10\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.37071876607573"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our point estimate for the mean would be the sample mean:\n",
    "\n",
    "Ybar = np.mean(sample)\n",
    "Ybar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which we expect to be normally distributed with mean $\\theta$ and variance $\\sigma^2 / \\sqrt{n}$.  The problem is that we do not know $\\sigma^2$.  We can use the sample variance $s^2$ instead, but it means rather than a normal distribution we expect that \n",
    "\n",
    "$$ T = \\sqrt{n} \\frac{\\bar{Y} - \\theta}{s} $$\n",
    "\n",
    "will satisfy the Student's T distribution with $n-1$ degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.496892605369556"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let me introduce you to the numpy.std function for finding standard deviations;\n",
    "# you need to pass it a ddof of 1 to get the sample standard deviation.\n",
    "\n",
    "s = np.std(sample, ddof=1)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step is to find the interval\n",
    "\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.860934606449914"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use symmetric tails with density 0.005\n",
    "\n",
    "a = -t.ppf(0.005, n-1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98999999999967"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that our interval has the correct density\n",
    "\n",
    "t.cdf(a, n-1) - t.cdf(-a, n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we now have is that:\n",
    "\n",
    "$$ 0.99 = P(-a < \\sqrt{n} \\frac{\\bar{Y} - \\theta}{s} < a ) $$\n",
    "\n",
    "Solving for $\\theta$ we get:\n",
    "\n",
    "$$ \\bar{Y} - \\frac{a s}{\\sqrt{n}} < \\theta < \\bar{Y} + \\frac{a s}{\\sqrt{n}} $$\n",
    "\n",
    "Or in other words $\\theta$ is in the following interval with 99% probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.5747734479190862, 13.166664084232373)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Ybar - a*s/np.sqrt(n), Ybar + a*s/np.sqrt(n) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Note that 99% confident is pretty confident. Redo the computaiton above but looking for an interval with only 90% confidence. 10% of the time we will have the wrong conclusion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7.477985959698341, 24.879406741880793)\n",
      "(9.277953916959827, 77.9889381510716)\n",
      "(4.338372721491339, 13.992406613032035)\n",
      "(7.463594750054622, 60.31831376424357)\n",
      "(7.188019956516205, 36.027356722177444)\n",
      "(8.967238261321958, 53.02527606605766)\n",
      "(5.902516531682981, 32.63761447475815)\n",
      "(7.2699523099716075, 25.802979580811957)\n",
      "(7.495644728782777, 13.012419336388493)\n",
      "(7.189229074117173, 28.866281413963748)\n",
      "(5.706330422072678, 30.5612745680189)\n",
      "(3.9732775170436874, 48.630525941911934)\n",
      "(6.998418061050199, 37.24616018547762)\n",
      "(4.286709315057645, 19.353782328583627)\n",
      "(4.2106487951102185, 11.523515730208675)\n",
      "(6.326189784960032, 30.438793275631593)\n",
      "(8.72889882950816, 29.552269169637153)\n",
      "(6.881272559967278, 37.06364137440315)\n",
      "(5.609617515601211, 33.113831379729504)\n",
      "(8.543122038981567, 40.60742687906016)\n",
      "(4.659622208682716, 25.985087147091107)\n",
      "(5.60706758750363, 24.12573354671986)\n",
      "(5.332104600080017, 32.952313598651145)\n",
      "(5.574947773390649, 44.76389508304808)\n",
      "(3.9765457192423135, 26.585922972951828)\n",
      "(5.993228537030594, 35.829497229474114)\n",
      "(4.692681858524633, 14.668168002393802)\n",
      "(6.0109945862774925, 16.294126920320537)\n",
      "(6.209864593979541, 37.9705502643461)\n",
      "(6.223142339771372, 30.987609672975317)\n",
      "(6.695301401837458, 25.091864297682083)\n",
      "(3.979697383617964, 14.28158505147552)\n",
      "(8.75196108797767, 61.755499239083015)\n",
      "(5.592041358924465, 24.383432790812748)\n",
      "(4.043359229199245, 21.963501588831505)\n",
      "(6.780501252496093, 35.691032673086596)\n",
      "(6.598143240017693, 31.641095532184476)\n",
      "(5.664611510239885, 26.848024235389744)\n",
      "(7.454023799614931, 45.677809620369615)\n",
      "(9.072327594979257, 46.76251781854478)\n",
      "(4.807730243736712, 13.927610211687782)\n",
      "(6.549261529870987, 37.21740985075603)\n",
      "(5.07781912893828, 24.116044550457573)\n",
      "(7.8441572783555324, 38.48867057264509)\n",
      "(9.00022900622694, 26.053722499006206)\n",
      "(7.481835191442996, 38.73092151016756)\n",
      "(7.8368259718661495, 44.50210504877026)\n",
      "(7.839451746221503, 24.901433629090484)\n",
      "(4.980977210716203, 32.679955245323825)\n",
      "(8.164765063438455, 40.75177222607853)\n",
      "(3.9188178121173545, 50.99494142771454)\n",
      "(6.867711896958815, 30.101752639894766)\n",
      "(5.0856235965475305, 18.368887120811635)\n",
      "(6.936209850458481, 27.1986600271144)\n",
      "(8.568181200581058, 65.7885712651988)\n",
      "(7.7356656823471734, 39.1457752205074)\n",
      "(3.444395148619802, 48.308841761124015)\n",
      "(7.142102621059326, 31.052136645896518)\n",
      "(7.187319042892022, 52.497485384997844)\n",
      "(8.120006306003127, 34.02361445601714)\n",
      "(9.028703331484252, 23.500838870508893)\n",
      "(8.960917357564018, 38.516794241254125)\n",
      "(3.3506772923043577, 12.17557548449767)\n",
      "(5.825963087752849, 23.827488552619585)\n",
      "(7.853312096995262, 62.04343262390577)\n",
      "(6.6206410573059244, 21.41509741977592)\n",
      "(3.45266402943571, 11.597491621637964)\n",
      "(9.156054276505778, 31.085638603652537)\n",
      "(5.27665380454682, 41.697717100841615)\n",
      "(4.652735706941142, 17.8361746814055)\n",
      "(6.555250455658408, 29.615982015230266)\n",
      "(8.398394203266268, 43.03693247849227)\n",
      "(5.758382147458365, 18.714429237636757)\n",
      "(9.935730999612604, 74.870244557929)\n",
      "(5.347365193484281, 72.7467294665135)\n",
      "(4.824805774539768, 27.005626056447692)\n",
      "\u001b[91m(10.633673853544925, 60.031156708873276)\u001b[0m\n",
      "(7.544497873324792, 33.00083544386767)\n",
      "(5.964923545430141, 15.427408137794446)\n",
      "(9.043558206104947, 23.16708263627349)\n",
      "(8.30955947779428, 31.15781439573832)\n",
      "(7.3454052486909145, 30.828259045814924)\n",
      "(5.6142482258630935, 32.47489782294483)\n",
      "(6.445912299366071, 25.57305983514578)\n",
      "(8.149093105399007, 49.86000999026223)\n",
      "(5.106010652806755, 20.583890469498016)\n",
      "(3.514890489912966, 25.543732525015688)\n",
      "(4.519643809437147, 26.782794601001207)\n",
      "(6.79120693499032, 33.030029924922765)\n",
      "\u001b[91m(11.07189389290388, 50.83578768302012)\u001b[0m\n",
      "(5.211331324210945, 86.72886092291378)\n",
      "(7.394248727400244, 26.595192921158603)\n",
      "(4.419532358400733, 21.122303758626636)\n",
      "(4.595934385570428, 32.900382916024206)\n",
      "(6.383143036591676, 19.850773406788072)\n",
      "(5.287549747416909, 20.569928089280054)\n",
      "(6.294744263402138, 27.549557186291896)\n",
      "(8.641870260565405, 30.073619708994237)\n",
      "(3.8158492137449707, 21.068595223390766)\n",
      "(4.955115686507741, 25.5996806835537)\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "\n",
    "for k in range(100):\n",
    "    sample = expon.rvs(size=n)*10\n",
    "    Ybar = np.mean(sample)\n",
    "    s = np.std(sample, ddof=1)\n",
    "    a = -t.ppf(0.05, n-1)\n",
    "    \n",
    "    l = Ybar - a*s/np.sqrt(n)\n",
    "    u = Ybar + s*s/np.sqrt(n)\n",
    "    \n",
    "    # check if 10 is in the interval and print in red; else print in black  \n",
    "    if l > 10 or u < 10:\n",
    "        print('\\033[91m' + str((l, u )) + '\\033[0m' )\n",
    "    else:\n",
    "        print((l, u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Differences\n",
    "\n",
    "The following prices of White Tuna Packed in Oil or Water were collected by sampling major brands at a local super market:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil = [1.27, 1.22, 1.19, 1.22]\n",
    "water = [1.49, 1.29, 1.27, 1.35, 1.29, 1.00, 1.27, 1.28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample means are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.225, 1.28)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(oil), np.mean(water)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to find a confidence interval for the difference between the population means for White Tuna Packed in Water or Oil. \n",
    "\n",
    "Note that we expect the statistic:\n",
    "\n",
    "$$ Z = \\frac{\\bar{Y_1} - \\bar{Y_2} - (\\mu_1 - \\mu_2) }{\\sqrt{ \\sigma_1^2/n_1 + \\sigma_2^2/n_2 }} $$\n",
    "\n",
    "to be a normally distributed. Assuming that $\\sigma$ is equal for the two populations this would be:\n",
    "\n",
    "$$ Z = \\frac{\\bar{Y_1} - \\bar{Y_2} - (\\mu_1 - \\mu_2) }{ \\sigma \\sqrt{ 1/n_1 + 1/n_2} } $$\n",
    "\n",
    "However note that for this problem we do not know $\\sigma_1$ or $\\sigma_2$, or $\\sigma$ for that matter. The assumption that two very similar products have the same variance is a common one so we could proceed with that and use what is called a **pooled estimator** for the $\\sigma$:\n",
    "\n",
    "$$ S_p^2 = \\frac{ (n_1 -1 ) S_1^2 + (n_2 - 1) S_2^2 }{n_1 + n_2 - 2} $$\n",
    "\n",
    "To explain where this comes from:  \n",
    "\n",
    "- note that we multiply the individual sample variances by their denominator.\n",
    "- We compute the sum of the squares of the differences of each sample from the corresponding sample mean and add these\n",
    "- then we divide by the degrees of freedom:  $n_1 + n_2 - 2$  The reason there are 2 less degrees of freedom is becuase we have two means.\n",
    "\n",
    "- The other way to think about the pooled estimator is that it is the weighted average of the sample variances; weighted by the number of degrees of freedom.\n",
    "\n",
    "Then we can use $S_p$ in our Student's T distirbution with $n_1 + n_2 - 2$ degrees of freedom:\n",
    "\n",
    "$$ T = \\frac{ \\bar{Y_1} - \\bar{Y_2} - (\\mu_1 - \\mu_2) }{ S_p \\sqrt{1/n_1 + 1/n_2} }$$\n",
    "\n",
    "We will get that:\n",
    "\n",
    "$$ (\\bar{Y}_1 - \\bar{Y}_2) \\pm t_{\\alpha/2} S_p \\sqrt{1/n_1 + 1/n_2} $$ \n",
    "\n",
    "gives the boundaries of our confidence interval where \n",
    "\n",
    "$$ P(-t_{\\alpha/2} < T < t_{\\alpha/2} ) = 1 - \\alpha $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5624488640252127, 0.6724488640252125)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing the computation:\n",
    "\n",
    "confidence = 0.99\n",
    "alpha = 1 - confidence\n",
    "\n",
    "\n",
    "# Compute the two sample means\n",
    "Ybar1 = np.mean(water)\n",
    "Ybar2 = np.mean(oil)\n",
    "\n",
    "# Record the sample sizes\n",
    "n1 = len(water)\n",
    "n2 = len(oil)\n",
    "dof = n1+n2-2\n",
    "\n",
    "# Compute the two sample standard deviations\n",
    "S1 = np.std(water, ddof = 1)\n",
    "S2 = np.std(oil, ddof = 1)\n",
    "\n",
    "# Compute the pooled sample standard deviation\n",
    "\n",
    "Sp = np.sqrt( ((n1-1)*S1 + (n2-2)*S2)/dof )\n",
    "\n",
    "# Compute the talpha\n",
    "\n",
    "talpha = -t.ppf(alpha/2, dof)\n",
    "\n",
    "# Give the confidence interval\n",
    "\n",
    "( (Ybar1 - Ybar2) - talpha * Sp *np.sqrt(1/n1 + 1/n2), (Ybar1 - Ybar2) + talpha * Sp *np.sqrt(1/n1+1/n2) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
