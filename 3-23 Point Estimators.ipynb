{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Estimators\n",
    "\n",
    "Spring Break provides a nice breaking point in our course. Our plan for the rest of the semester is to apply what we have learned so far to answering some question. Specifically we would like to develop techniques for making inferences and conclusions from statistical data. \n",
    "\n",
    "To that end we will have a series of examples to illustrate what we want to do:\n",
    "\n",
    "## How much to bid\n",
    "\n",
    "A construction company is putting a bid in on a new building project. Comparable projects have cost the company 535, 540, 545, 546, and 600 dollars per square foot. To compute the bid to submit we need to come up with an estimate on the cost per square foot for the project, the decision is to find an estimate for this from the mean cost per square foot. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553.2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [535, 540, 545, 546, 600]\n",
    "Ybar = np.mean(data)\n",
    "Ybar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obvious estimate is of course the sample mean from the data we have:  553.20 dollars. \n",
    "\n",
    "The first concern is:  What do we expect the error of this estimate to be?\n",
    "\n",
    "### Unbiased Estimator\n",
    "\n",
    "Let $\\hat{\\theta}$ be an estimator for a statistics $\\theta$. Of course a good estimator will have the property that the expected value of it is the parameter we are trying to find:  $$ E(\\hat{\\theta}) = \\theta$$  and for example $\\bar{Y}$ as an estimator for $\\mu$ has that property. \n",
    "\n",
    "This is called an unbiased estimator.\n",
    "\n",
    "#### Example\n",
    "\n",
    "The 553.20 above is our unbiased estimate of the mean cost for similar jobs. \n",
    "\n",
    "### Biased Estimators\n",
    "\n",
    "Of course there are examples (like above) where maybe what we want is a biased estimator. \n",
    "\n",
    "**Example** the construction company may want to protect against loses over getting a contract, and so inflating the cost estimate so that its expected outcome is higher than the mean might be worthwhile to hedge against an expensive job.\n",
    "\n",
    "The *Bias* of an estimator is defined to be:  $$ B(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta$$\n",
    "\n",
    "A simple bias on our esimtator above might be achieved by adding a factor to $\\bar{Y}$ such as $S/\\sqrt{n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.527344382730814"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample standard deviation is\n",
    "\n",
    "S = np.sqrt(sum( [ (data[i] - Ybar)**2 for i in range(5)])/4)\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565.0633890604668"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positive Biased Estimate is\n",
    "\n",
    "theta_hat = Ybar + S/np.sqrt(5)\n",
    "theta_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously the expense of introducing a bias (at least in this example) is going to be an increase in the error. The point is that we are adding error we consider acceptable (over estimates) and subtracting errors we consider less acceptable (under estimates)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square Error\n",
    "\n",
    "Of course our other concern is what we expect the error between $\\hat{\\theta}$ and $\\theta$ to be. The *Mean Square Error* is defined (in the obvious way) by:\n",
    "\n",
    "$$ \\mbox{MSE}(\\hat{\\theta}) = E (\\hat{\\theta} - \\theta)^2 ) $$\n",
    "\n",
    "The mean square error of an estimator is a function of both its variance (how much we expect the estimator to vary if we repeate the experiment) and its bias (how much we expect the estimators expected value to differ from the statistic). \n",
    "\n",
    "$$\\mbox{MSE}(\\hat{\\theta}) = V(\\hat{\\theta}) + B(\\hat{\\theta})^2 $$\n",
    "\n",
    "Interestingly, put this way, all of the dependence on $\\theta$ itself is contained in the bias.\n",
    "\n",
    "### Example - $\\bar{Y}$\n",
    "\n",
    "So for the unbiased estimator of the mean we have:\n",
    "\n",
    "$$ \\mbox{MSE}(\\bar{Y}) = V(\\bar{Y}) = \\sigma^2 / 5 $$ \n",
    "\n",
    "If we know $\\sigma$. We do not know $\\sigma$ so our estimate would replace this with $S$. That fact that $S$ is not $\\sigma$ will show up in our computation of the probabilities for error bounds and intervals on Thursday (i.e. we will use a t-distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140.74"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = S**2 / 5\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example - $\\bar{Y} + S/\\sqrt{n}$\n",
    "\n",
    "Here we compute the mean square error by adding in the bias $S/2$ term:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281.48"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_bias = S**2 / 5 + S**2 / 5\n",
    "MSE_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.863389060466659, 16.77736570502056)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(MSE), np.sqrt(MSE_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Estimators for $\\sigma$\n",
    "\n",
    "So we have seen our first example that $\\bar{Y}$ is an unbiased point estimator for $\\mu$. If the population from which we are sampling is normal then it is in fact the best (lowest MSE) unbiased estimator for $\\mu$. Note that for example if the population is uniformly distributed in some interval there are better unbiased estimators of $\\mu$.\n",
    "\n",
    "Now let's consider estimated the population variance (or standard deviation). \n",
    "\n",
    "Someone who was just joining our class today might suspect that:\n",
    "\n",
    "$$ S'^2 = \\frac{1}{n} \\sum (Y_i - \\bar{Y})^2 $$\n",
    "\n",
    "would be a good estimator. However it turns out that this estimator is biased.\n",
    "\n",
    "$$ \\sum (Y_i - \\bar{Y})^2 = \\sum Y_i^2 - n \\bar{Y}^2 $$\n",
    "\n",
    "So that\n",
    "\n",
    "$$ E( S'^2 ) = \\frac{1}{n} \\left[ \\sum E(Y_i^2) - n E(\\bar{Y}^2) \\right] $$\n",
    "\n",
    "Note that $E(Y_i^2)$ is the same for all i, $\\sigma^2 + \\mu^2$ and that $E(\\bar{Y}^2) = \\sigma^2/n + \\mu^2$ giving us:\n",
    "\n",
    "$$ E( S'^2 )=\\frac{1}{n} \\left[ n (\\sigma^2 + \\mu^2) - n (\\sigma^2/n + \\mu^2)\\right] = \\frac{(n-1)}{n} \\sigma^2$$\n",
    "\n",
    "Which for a fixed n is strictly smaller than $\\sigma^2$. Meaning $S'^2$ is a left biased estimator of $\\sigma^2$. \n",
    "\n",
    "This then explains where the $\\frac{1}{n-1}$ comes from in our sample variance formula - it gives us an unbiased estimator of $\\sigma^2$ for all $n$.\n",
    "\n",
    "Note that as $n$ becomes large this issue becomes smaller - the size of the bias does go to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - Proportions\n",
    "\n",
    "Colorado is trying to understand how many people have been vaccinated for COVID-19 so far. A random phone poll of 120 Coloradans finds 33 who have received at least one shot of vaccine for COVID-19. \n",
    "\n",
    "Our estimate for the proportion of Coloradans who have received at least one shot of vaccine is then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.275"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phat = 33/120\n",
    "phat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an unbiased estimate for the true value of $p$. The Mean Square Error for proportion estimates is\n",
    "\n",
    "$$ \\mbox{MSE}(\\hat{p}) = \\frac{p q}{n} $$\n",
    "\n",
    "and so our estimate of that error here is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04076099033798533"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = phat*(1-phat)/120\n",
    "np.sqrt(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that the area under the normal distribution within two standard deviations of the mean contains about 95% of the density of the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9544997361036416"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.cdf(2) - norm.cdf(-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also recall that the binomial distribution can be modeled as a normal distribution for large $n$. So a 95.45% error bound on our estimate of $\\hat{p} = 0.275$ would be given by:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19347801932402936, 0.3565219806759707)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phat - np.sqrt(MSE)*2, phat + np.sqrt(MSE)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08152198067597066"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(MSE)*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we might phrase this as the proportion is estimated to be $0.9275 \\pm 0.0815 $ (with 95% confidence)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - How big of a sample\n",
    "\n",
    "Note the change if we double the sample size:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02882237267586877"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = phat*(1-phat)/240\n",
    "np.sqrt(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2173552546482625, 0.33264474535173755)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phat - np.sqrt(MSE)*2, phat + np.sqrt(MSE)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05764474535173754"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(MSE)*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course its more subtle because changing the sample will change our $\\hat{p}$.\n",
    "\n",
    "## Example - Difference of Two Proportions\n",
    "\n",
    "This result will rely on the unsurprising fact that if $Y_1$ and $Y_2$ are normal distributions with means $\\mu_1$ and $\\mu_2$, and variances $\\sigma_1^2$ and $\\sigma_2^$ then $U = Y_1 - Y_2$ is normal with mean \n",
    "\n",
    "$$ E(Y_1 - Y_2) = \\mu_1 - \\mu_2 $$\n",
    "\n",
    "and variance \n",
    "\n",
    "$$ V(Y_1 - Y_2 ) = \\sigma_1^2 + \\sigma_2^2 $$\n",
    "\n",
    "Together with again using the normal estimate for a binomial.\n",
    "\n",
    "### Vaccine Rates\n",
    "\n",
    "Colorado has vaccinated 13.3% of its 5.8 million population. Arkansas has vaccinated 18.9% of its 0.7 million population based on surveys of 500 people in each state. What do we expect the difference in proportions to be and with what error range for 95% confidence?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.055999999999999994"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# difference phat_1 - phat_2 \n",
    "\n",
    "phat1 = 0.133\n",
    "phat2 = 0.189\n",
    "\n",
    "phatdiff = phat1 - phat2\n",
    "phatdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005371800000000001"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE is from adding the MSE of each:\n",
    "\n",
    "MSEdiff = phat1*(1-phat1)/(500) + phat2*(1-phat2)/(500)\n",
    "MSEdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04635428782755701"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * np.sqrt(MSEdiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the error of the difference between the state's proportions is on the order of 4.6% to either side of -5.6 percent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Point Estimators\n",
    "\n",
    "Generally point estimators exist for any parameter relevant to a distribution. A favorite of mine is the following example because it is so different from the normal based ones above:  And because it produces something similar to the sample variance formula showing again why the work we are doing here matters.\n",
    "\n",
    "Let $Y_1, Y_2, \\dots, Y_n$ be a sample from a uniform distribution on the interval $(0, \\theta)$. What is an estimate for $\\theta$?\n",
    "\n",
    "### Obvious approach\n",
    "\n",
    "We found the distribution of $max(Y_1, \\dots, Y_n) = Y_{(n)} $ previously. It is given by the density function:\n",
    "\n",
    "$$ g_{(n)}(y) = n ( F_Y(y) )^{n-1} f(y) = \\left\\{ \\begin{matrix} n \\left(\\frac{y}{\\theta} \\right)^{n-1} \\frac{1}{\\theta} & 0 \\leq y \\leq \\theta \\\\ 0 & \\mbox{otherwise} \\end{matrix} \\right. $$\n",
    "\n",
    "and of course $Y_{(n)}$ is a great estimate for $\\theta$. \n",
    "\n",
    "#### Is it biased\n",
    "\n",
    "Let's compute $E(Y_{(n)})$?  Well before we compute it. What do you think?  Will it be biased?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5*y**4/theta**5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy as sp\n",
    "\n",
    "y = sp.Symbol('y')\n",
    "n = 5\n",
    "# for reasons fixing n is better\n",
    "theta = sp.Symbol('theta')\n",
    "\n",
    "g = n* y**(n-1) /theta**n\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5*theta/6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.integrate(y* g, (y, 0, theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed we see it is biased. Play with the code and convince yourslef that \n",
    "\n",
    "$$ \\hat{\\theta} = \\frac{n+1}{n} Y_{(n)} $$ \n",
    "\n",
    "is an unbiased estimator of $\\theta$. Note that this is essentially a correction taking into account that we have a limited sample and that none of our sample can be larger than $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance of $\\frac{n+1}{n} Y_{(n)} $\n",
    "\n",
    "To compute the MSE of our unbiased estimator we need to compute the variance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "theta**2/35"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V(Y_{(n)} is given by \n",
    "\n",
    "thetahat = (n+1)*y/n\n",
    "sp.integrate( (thetahat - theta)**2 * g, (y, 0, theta) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be able to show:  $$ V( \\frac{n+1}{n} Y_{(n)} )= \\frac{\\theta^2}{n (n+2) } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Approach\n",
    "\n",
    "Another idea is to recall that the Expected Value of $\\bar{Y}$ is $\\theta/2$ and so our other estimator could be:\n",
    "\n",
    "$$ \\hat{\\theta}_2 = 2 \\bar{Y}$$\n",
    "\n",
    "#### Is it biased\n",
    "\n",
    "We can quickly compute $$ E(2 \\bar{Y}) = \\theta $$\n",
    "\n",
    "#### MSE \n",
    "\n",
    "It's mean square error comes from $$ V(2 \\bar{Y}) = 4 V(\\bar{Y}) = \\frac{4}{n} V(Y_1) = \\frac{\\theta^2}{3 n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing two unbiased estimators\n",
    "\n",
    "When given two unbiased estimators, the ratio of their MSE gives a measure of what we call *relative efficiency* with the idea that an esimator with less error, biases being irrelevant, is producing better results:\n",
    "\n",
    "$$ \\mbox{eff}( \\frac{n+1}{n} Y_{(n)}, 2 \\bar{Y} ) = \\frac{ V( 2\\bar{Y}) }{ V( \\frac{n+1}{n} Y_{(n)} ) } = \\frac{n (n+2)}{3n} = \\frac{n+2}{3} $$\n",
    "\n",
    "If the efficiency is bigger than 1 then the first estimator is considered better; if the efficiency is less then 1 than the second would be considered better.\n",
    "\n",
    "In this case we see that for $n> 1$ the first estimator is more effiicient. Does this make sense?\n",
    "\n",
    "### Effeciency is a bad word here\n",
    "\n",
    "Of course there are other problems with effeciency. A new probably confronting statisticians and data scientists is when they have to much data and computing an estimator from the data becomes inefficient. In the example above one can compute both in O(n) operations so they are approximately equivalent computationally. But sorting in particular is computationally intensive and so you can imagine examples using the other $Y_{(k)}$ that would become computationally complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Finding new estimators is a fun business. In most cases, for known distributions and the standard parameters, we have known best unbiased estimators available (google and wikipedia can help you find them). Where the work goes is, looking back at our initial problem, when we have a specific problem that is necessitating an biased estimate of one kind or another. To find these means we are giving up on best in the MSE sense and are now trying to minimize something else. \n",
    "\n",
    "You can write a PhD thesis about solving one of these problems!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
