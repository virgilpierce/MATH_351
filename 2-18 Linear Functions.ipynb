{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "2-18 Linear Functions.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVnHG32F93dQ"
      },
      "source": [
        "### Implication\n",
        "\n",
        "This implies that if $Y_1$ and $Y_2$ are independent, then the $\\mbox{Cov}(Y_1, Y_2)$ is zero. However note that the converse is not true. I.e. just because the Covariance is zero, does not mean the variables are inedpendent. See the next example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS0ZrZHs93dU"
      },
      "source": [
        "### Example\n",
        "\n",
        "Suppose that $Y_1$ and $Y_2$ are uniformly distributed over the triangle given by:  $-1 \\leq Y_1 \\leq 1 $ and $ 0 \\leq Y_2 \\leq 1 - |Y_1| $.\n",
        "\n",
        "- Find the normalizing constant that makes the constant function of this region a valid PDF.\n",
        "- Find the $Cov(Y_1, Y_2) = E( Y_1 Y_2) - E( Y_1) E(Y_2) $\n",
        "- Find the coefficient of correlation for $Y_1$ and $Y_2$.\n",
        "- Discuss:  Are $Y_1$ and $Y_2$ dependent or independent?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT1ccQGVI9zV",
        "outputId": "99fcbd56-1fc4-45fa-c0cd-674670b9d5ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sympy as sp\r\n",
        "\r\n",
        "y1 = sp.Symbol('y1')\r\n",
        "y2 = sp.Symbol('y2')\r\n",
        "sp.integrate(1, (y1, y2-1, 1-y2), (y2, 0, 1) )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSLseU7qJh2W",
        "outputId": "775effc6-220a-4b43-bf6b-45a007811c12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Ey1 = sp.integrate( y1, (y1, y2-1, 1-y2), (y2, 0, 1) ) \r\n",
        "Ey1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhIhOBgDJxdX",
        "outputId": "6f01b7e3-3d8f-495a-81b5-1e74c1b43af0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Ey2 = sp.integrate( y2, (y1, y2-1, 1-y2), (y2, 0, 1) ) \r\n",
        "Ey2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1/3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XanpBR2QJxgn",
        "outputId": "da1c8ad3-1c80-4eb9-8028-97d8412410ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Ey1y2 = sp.integrate( y1*y2, (y1, y2-1, 1-y2), (y2, 0, 1) ) \r\n",
        "Ey1y2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OBdgyGzJxkO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph7ljub1Jxo8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpzFDH0693dV"
      },
      "source": [
        "## Correlation versus Dependence\n",
        "\n",
        "So we say that variables are uncorrelated if $\\mbox{Cov}(Y_1, Y_2) = 0 $\n",
        "\n",
        "Wheras they are independent if $P( Y_1 < y_1, Y_2 < y_2) = P_1(Y_1 < y_1) P_2(Y_2 < y_2)$.\n",
        "\n",
        "And independents implies uncorrelated, but uncorrelated does not imply indepdence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxWj3h3t93dV"
      },
      "source": [
        "# Expected Values, Variances, and Covariances of Linear Functions of Random Variables\n",
        "\n",
        "We need a motivating example for what we are about derive. So lets look ahead to what we want to do:\n",
        "\n",
        "## Sampling\n",
        "\n",
        "We are interested in understanding what happens when we have a random variables $Y$ and we sample it $n$ times to get $Y_1, Y_2, \\dots Y_{n}$ and then compute a single statistic from those results, say the mean. \n",
        "\n",
        "$$ \\bar{Y} = \\frac{1}{n} Y_1 + \\frac{1}{n} Y_2 + \\dots + \\frac{1}{n} Y_n $$\n",
        "\n",
        "Written this way, we see that we can think of this as having $Y_i$ independent random variables each with $E(Y_i) = \\mu $ and $V(Y_i) = \\sigma$ coming from the original random varialbe $Y$. \n",
        "\n",
        "**Question:** Find $ E(\\bar{Y})$ and $V(\\bar{Y})$. I.e. how do we expect the statistics computed from our sample to behave?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0crN164Mj3w"
      },
      "source": [
        "$$ E(\\bar{Y}) = E( \\frac{1}{n} Y_1 + \\frac{1}{n} Y_2 + \\dots + \\frac{1}{n} Y_n ) = E(\\frac{1}{n} Y_1) + E( \\frac{1}{n} Y_2) + \\dots + E( \\frac{1}{n} Y_n ) = n \\frac{\\mu}{n} = \\mu $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5Y9ycsm93dW"
      },
      "source": [
        "*Hint* Hint we might want to use that $$V(\\bar{Y}) = E( \\bar{Y}^2 ) - E(\\bar{Y})^2$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLbHLbHANRjg"
      },
      "source": [
        "We need to find\r\n",
        "\r\n",
        "$$ E(\\bar{Y}^2 ) $$\r\n",
        "\r\n",
        "$$\\bar{Y}^2 = \\sum_{i, j} \\frac{1}{n^2} Y_i Y_j $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF2tnbSrNmef"
      },
      "source": [
        "When $i\\neq j$ \r\n",
        "\r\n",
        "$$ E(Y_i Y_j) = E(Y_i) E(Y_j) = \\mu^2 $$\r\n",
        "\r\n",
        "$$ E(Y_i^2) = \\sigma + \\mu^2 $$\r\n",
        "\r\n",
        "Inserting this into the sum we get:\r\n",
        "\r\n",
        "$$ E(\\bar{Y}^2) = \\mu^2 + \\frac{1}{n} \\sigma $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aZ_CHhEOfYV"
      },
      "source": [
        "So\r\n",
        "\r\n",
        "$$ V(\\bar{Y}) = \\mu^2 + \\frac{\\sigma}{n} - \\mu^2 = \\frac{\\sigma}{n} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk8EJ-tz93dW"
      },
      "source": [
        "## Linear Functions of Random Variables\n",
        "\n",
        "More generally let the $Y_i$ and $X_j$ be (possibly dependent) random variables, and \n",
        "\n",
        "$$ U_1 = \\sum_j a_j Y_j $$ and $$ U_2 = \\sum_j b_j X_j$$ be linear functions of these random variables. Then\n",
        "\n",
        "$$ E(U_1) = \\sum_j a_j E(Y_j) $$\n",
        "\n",
        "$$ V(U_1) = E( U_1^2 ) - E(U_1)^2 = \\sum a_j^2 V(Y_j) + 2 \\sum_{i<j} a_i a_j \\mbox{Cov}(Y_i, Y_j) $$\n",
        "\n",
        "and \n",
        "\n",
        "$$ \\mbox{Cov}(U_1, U_2) = \\sum_{i, j} a_i b_j \\mbox{Cov}(Y_i, X_j) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIjfg4lr93dW"
      },
      "source": [
        "# Conditional Expecations\n",
        "\n",
        "Finally there some neat tricks we can play with conditional probabilities and expectations. \n",
        "\n",
        "Given two random variables $Y_1$ and $Y_2$, we define *Conditional Expectation* of $g(Y_1)$ given $Y_2=y_2$ to be \n",
        "\n",
        "$$ E(g(Y_1) | Y_2=y_2) = \\int g(y_1) f(y_1 | y_2 ) dy_1 $$\n",
        "\n",
        "Where $f(y_1 | y_2) $ is the conditional PDF. \n",
        "\n",
        "## Expected Values \n",
        "\n",
        "Then note if we take the expected value of the conditional expected value we get back to just the expected value in $Y_1$:\n",
        "\n",
        "$$ E( E(Y_1 | Y_2) ) = E( Y_1 )$$\n",
        "\n",
        "## Variances\n",
        "\n",
        "More interestingly if we consider variances:\n",
        "\n",
        "$$ V(Y_1) = E[ V(Y_1 | Y_2) ] + V[ E( Y_1 | Y_2 ) ] $$\n",
        "\n",
        "where $$ V( Y_1 | Y_2) = E( Y_1^2 | Y_2) - [ E(Y_1 | Y_2 ) ]^2$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P72mNxq693dX"
      },
      "source": [
        "### Example\n",
        "\n",
        "It is maybe not clear why these conditional expectations and the related theorems are useful. They come up frequently in models where the parameters of the random distribution are themselves unkown. Consider:  \n",
        "\n",
        "The viral load of person with COVID-19 is $Y$ in virus particulates per mg of saliva, and fits an exponential distribution with the $\\beta$ parameter a uniformly distributed random variable between $(0, 200)$. I.e. the evidence is that the $\\beta$ parameter itself changes from infection to infection.\n",
        "\n",
        "For a given $\\beta$ the expected value and variance of $Y$ are known: $$ E(Y | \\beta) = \\beta $$ and $$ V(Y | \\beta) = \\beta^2 $$\n",
        "\n",
        "Find the $E(Y)$ and $V(Y)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADvtxeSk93dX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}