{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall\n",
    "\n",
    "Recall that we have Bayes Theorem, written in terms of some hypothesis H and observations (data, experiments, etc) D.\n",
    "\n",
    "$$ P(H|D) = \\frac{ P(H) P(D|H) }{ P(D) } $$\n",
    "\n",
    "We think of this as updating our assumption, the prior estimate $P(H)$ to account for the results of experiement. \n",
    "\n",
    "### Example - Monty Hall\n",
    "\n",
    "The classic example is the Monty Hall Problem.  On the game show *Let's Make a Deal*, one of the games was that there was a new car hidden behind one of 3 doors. The contestant choose one of the doors. Monty would then open one of the other two doors to show that there was no car behind it, and then ask the contestant:  *would you like to change your guess?* \n",
    "\n",
    "The question that appears in almost every Probability and Stats Class is:  What should the contestant do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - Dice\n",
    "\n",
    "Suppose I have a box of dice that contains a 3 sided die, a 6 sided die, an 8 sided die, a 12 sided die, and a 20 sided die. I selected a die from the box and roll it and get a 6. Find the probability that the die I selected is each of the dice in the box.\n",
    "\n",
    "You need to choose a representation for the hypotheses, a representation for the data, and then find the **prior**, **likliehood** and **posterior**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - The Locomotive Problem\n",
    "\n",
    "A variation on a problem from Frederick Mosteller's *Fifty Challenging Problems in Probability with Solutions*. A Mathematics Department has N sections of College Algebra labeled 1 through N. You drop by their campus and are taken to a course with the section number 15. What do we expect N to be?\n",
    "\n",
    "This one is different from the others in that we do not really know what the **prior** should be. Choose something and then proceed. Then we will need to ask what the consequence of our choice was.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion - The German Tank Problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inferences\n",
    "\n",
    "Recall that we have Bayes Theorem, written in terms of some hypothesis H and observations (data, experiments, etc) D.\n",
    "\n",
    "$$ P(H|D) = \\frac{ P(H) P(D|H) }{ P(D) } $$\n",
    "\n",
    "We think of this as updating our assumption, the prior estimate $P(H)$ to account for the results of experiement. \n",
    "\n",
    "This gives a diferent way for us to think about conficence interval and hypothesis tests we have been doing in this class.\n",
    "\n",
    "### Consider the following example:\n",
    "\n",
    "RU-486 is claimed to be an effective “morning after” contraceptive pill, but is it really effective?\n",
    "\n",
    "Data: A total of 40 women came to a health clinic asking for emergency contraception (usually to prevent pregnancy after unprotected sex). They were randomly assigned to RU-486 (treatment) or standard therapy (control), 20 in each group. In the treatment group, 4 out of 20 became pregnant. In the control group, the pregnancy rate is 16 out of 20.\n",
    "\n",
    "Do we have enough evidence to conclude that the RU-486 is effective?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider just the 20 preganancies in the trial. How likely is it that of those 20 pregnancies, only 4 of them appeared in the RU-486 group?  If the drug is ineffective the proportion should be 0.5. So form this point of view our hypothesis is $H_0: p = 0.5$. The question is then in a binomial trial with 20 pregnancies and a $p=0.5$ how likely is it that only 4 or fewer of them are successes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005908966064453125"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fact(n):\n",
    "    \n",
    "    if n > 1:\n",
    "        return n*fact(n-1)\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def binom(n, m):\n",
    "    \n",
    "    return fact(n)/( fact(m) * fact(n-m) )\n",
    "\n",
    "\n",
    "\n",
    "p = 0.5\n",
    "sum( [ p**k * (1-p)**(20 - k) * binom(20, k) for k in range(5) ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we see that this is an outcome we would expect less than 1% of the time.\n",
    "\n",
    "The precise phisophical statement we are making is that you could repeate this experiment 100 times you would expect to get this outcome only once if the true proportion were 0.5.\n",
    "\n",
    "## Example Bayes Approach\n",
    "\n",
    "Okay so now let's do the same problem but from the point of view of Bayes's theorem. What we will do is try and compute the probability p, that a given pregnancy comes from the control group. If there is no difference between test and control we should be concluding that p = 0.5.\n",
    "\n",
    "We will compute the Bayesian results for a range of p values (I'll explain why when we get to it). To make our lives easy we can just work with a set of discrete values, but you need to use enough of them to discern a difference (think about the significance level we were discussing before):\n",
    "\n",
    "Let's take the hypothesis:  p = 0.1, 0.2, ..., 0.8, 0.9.\n",
    "\n",
    "We need to make prior estimates for how likely these propotions are (without reference to the observation of k=4). Our belief prior to the observations, reflecting the null hypothesis is that p=0.5 is most likely and that the other probabilities are equally (and non-zero) likely. We could use 0.52 for p=0.5; and 0.06 for the other 8. But note this is a choice, there are some rules about how to proceed in general.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: 0.06,\n",
       " 0.2: 0.06,\n",
       " 0.3: 0.06,\n",
       " 0.4: 0.06,\n",
       " 0.5: 0.52,\n",
       " 0.6: 0.06,\n",
       " 0.7: 0.06,\n",
       " 0.8: 0.06,\n",
       " 0.9: 0.06}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_model = { 0.1:0.06, 0.2:0.06, 0.3:0.06, 0.4:0.06, 0.5:0.52, 0.6:0.06, 0.7:0.06, 0.8:0.06, 0.9:0.06}\n",
    "P_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The total probability for our models needs to be 1\n",
    "\n",
    "sum( P_model.values() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compute the likliehoods:  $$ P(k=4 | n=20, p)$$\n",
    "\n",
    "Note this is just a binomial probability:  $p^4 (1-p)^{16} \\binom{20}{4} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: 0.08977882814987174,\n",
       " 0.2: 0.21819940194610074,\n",
       " 0.3: 0.1304209743738705,\n",
       " 0.4: 0.03499079040415824,\n",
       " 0.5: 0.004620552062988281,\n",
       " 0.6: 0.0002696861504765954,\n",
       " 0.7: 5.00755833151246e-06,\n",
       " 0.8: 1.3005697843199956e-08,\n",
       " 0.9: 3.1788044999999885e-13}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_data_model = {}\n",
    "\n",
    "for p in P_model:\n",
    "    \n",
    "    P_data_model[p] = p**4 * (1-p)**(20-4) * binom(20, 4)\n",
    "    \n",
    "P_data_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: 0.005386729688992305,\n",
       " 0.2: 0.013091964116766044,\n",
       " 0.3: 0.007825258462432231,\n",
       " 0.4: 0.0020994474242494944,\n",
       " 0.5: 0.0024026870727539063,\n",
       " 0.6: 1.6181169028595726e-05,\n",
       " 0.7: 3.004534998907476e-07,\n",
       " 0.8: 7.803418705919973e-10,\n",
       " 0.9: 1.907282699999993e-14}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then we find the numerators of our Bayes probabilities\n",
    "\n",
    "P_model_data_model = {}\n",
    "for p in P_model: \n",
    "    \n",
    "    P_model_data_model[p] = P_model[p] * P_data_model[p] \n",
    "    \n",
    "P_model_data_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030822569168083413"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P(data) is then found by summing these results:\n",
    "\n",
    "P_data = sum( P_model_data_model.values() )\n",
    "P_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: 0.1747657588054091,\n",
       " 0.2: 0.42475252615614845,\n",
       " 0.3: 0.2538807981826265,\n",
       " 0.4: 0.06811396586704588,\n",
       " 0.5: 0.07795219988481279,\n",
       " 0.6: 0.0005249779452308353,\n",
       " 0.7: 9.747840884135817e-06,\n",
       " 0.8: 2.531722343898693e-08,\n",
       " 0.9: 6.18794199016665e-13}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and that brings us to our final result the posterior estimates of P_model_data\n",
    "\n",
    "P_model_data = {}\n",
    "for p in P_model:\n",
    "    \n",
    "    P_model_data[p] = P_model_data_model[p] / P_data\n",
    "    \n",
    "P_model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of things:  While we started with a prior estimate of the distribution that favored the null hypothesis, the experiment gave us an updated likliehood with p = 0.2 now showing up as the most likely probability, and p=0.5 now rated at just 8%. If we combine the probabilities for p< 0.5 we find:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9215130490112299"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_model_data[0.1] + P_model_data[0.2] + P_model_data[0.3] + P_model_data[0.4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning our posterior probabilities estimate a 92% chance that $p< 0.5$ and so we are concluding that the drug is effective. Note in this case it is explicitly a statement about the likliehood that the value of p has a particular value based on the educated estimates prior to the experiment and the update following the experiment.\n",
    "\n",
    "Note also that it is not quite as strong a conclusion as we had in the experimentalist approach. This is due, computationally to our prior estimate (see below) but also reflects our thinking about the problem.\n",
    "\n",
    "### Effect of the Prior\n",
    "\n",
    "A big concern about Bayesian methods is the effect of the prior estimate. Consider the previous computation, but suppose we double the sample size and the result successes from k=4 to k=8. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you see happening is that any prior estimate we make will be dominated by the likliehoods, provided the sample sizes are large enough. The only caveat is that a prior estimate of 0 for one of our probabilities cannot be adjusted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
